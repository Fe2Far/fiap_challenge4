{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f469e0d8-3679-429b-a50c-20b5b4db61ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Acur√°cia do Modelo: 98.35%\n",
      "\n",
      "üìä Relat√≥rio de Classifica√ß√£o:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       1.00      0.98      0.99        54\n",
      "      Normal_Weight       0.93      0.98      0.96        58\n",
      "     Obesity_Type_I       0.99      1.00      0.99        70\n",
      "    Obesity_Type_II       0.98      0.98      0.98        60\n",
      "   Obesity_Type_III       1.00      0.98      0.99        65\n",
      " Overweight_Level_I       0.98      0.95      0.96        58\n",
      "Overweight_Level_II       1.00      1.00      1.00        58\n",
      "\n",
      "           accuracy                           0.98       423\n",
      "          macro avg       0.98      0.98      0.98       423\n",
      "       weighted avg       0.98      0.98      0.98       423\n",
      "\n",
      "\n",
      "‚úÖ Arquivos 'pipeline_obesidade.pkl' e 'label_encoder.pkl' salvos com sucesso na pasta fiap_challenge4!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# 1. Carregamento dos Dados\n",
    "df = pd.read_csv('Obesity.csv')\n",
    "\n",
    "# 2. Limpeza de Dados (Data Cleaning)\n",
    "# Arredondando as colunas que possuem ru√≠do decimal para o inteiro mais pr√≥ximo\n",
    "colunas_com_ruido = ['FCVC', 'NCP', 'CH20', 'FAF', 'TUE']\n",
    "\n",
    "# Verifica se as colunas existem antes de aplicar (previne erros se o CSV tiver varia√ß√µes de nome, como CH2O em vez de CH20)\n",
    "for col in colunas_com_ruido:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].round().astype(int)\n",
    "    else:\n",
    "        # Tratamento de fallback caso o CSV original difira levemente do PDF\n",
    "        if col == 'CH20' and 'CH2O' in df.columns:\n",
    "             df['CH2O'] = df['CH2O'].round().astype(int)\n",
    "        if col == 'TUE' and 'TER' in df.columns:\n",
    "             df['TER'] = df['TER'].round().astype(int)\n",
    "\n",
    "# 3. Engenharia de Atributos (Feature Engineering)\n",
    "# Criando a coluna de IMC (√çndice de Massa Corporal)\n",
    "df['IMC'] = df['Weight'] / (df['Height'] ** 2)\n",
    "\n",
    "# 4. Separa√ß√£o das Vari√°veis\n",
    "X = df.drop('Obesity', axis=1) # Atualizado para o nome correto do dicion√°rio\n",
    "y = df['Obesity']\n",
    "\n",
    "# Codificando a vari√°vel alvo (Target)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# 5. Configura√ß√£o do Pr√©-processamento\n",
    "# Atualizando as listas com os nomes exatos do dicion√°rio\n",
    "# Verificamos dinamicamente os nomes de CH20/CH2O e TUE/TER para evitar quebra no Pipeline\n",
    "agua_col = 'CH20' if 'CH20' in df.columns else 'CH2O'\n",
    "tech_col = 'TUE' if 'TUE' in df.columns else 'TER'\n",
    "\n",
    "num_features = ['Age', 'Height', 'Weight', 'IMC', 'FCVC', 'NCP', agua_col, 'FAF', tech_col]\n",
    "cat_features = ['Gender', 'family_history', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_features)\n",
    "    ])\n",
    "\n",
    "# 6. Constru√ß√£o do Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# 7. Divis√£o de Treino e Teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# 8. Treinamento do Modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 9. Avalia√ß√£o\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acuracia = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"üéØ Acur√°cia do Modelo: {acuracia * 100:.2f}%\\n\")\n",
    "print(\"üìä Relat√≥rio de Classifica√ß√£o:\")\n",
    "target_names = le.inverse_transform(np.unique(y_encoded))\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# 10. Exporta√ß√£o dos Artefatos para o Deploy\n",
    "joblib.dump(pipeline, 'pipeline_obesidade.pkl')\n",
    "joblib.dump(le, 'label_encoder.pkl')\n",
    "print(\"\\n‚úÖ Arquivos 'pipeline_obesidade.pkl' e 'label_encoder.pkl' salvos com sucesso na pasta fiap_challenge4!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029fda6a-4bfe-4f82-809f-8c00f5fdd939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
